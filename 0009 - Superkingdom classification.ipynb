{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3994e697",
   "metadata": {},
   "source": [
    "# Taxonomic classification: superkingdom prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b5bf6f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-14 16:55:33.648537: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from sequence_pairs import SampleList, make_cgr\n",
    "from ete3 import NCBITaxa\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, RidgeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.metrics import confusion_matrix, pairwise, roc_auc_score, roc_curve\n",
    "from sklearn.feature_selection import VarianceThreshold, chi2, SelectKBest, SelectPercentile\n",
    "from sklearn.model_selection import GridSearchCV, RepeatedStratifiedKFold, RepeatedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import simple_cgr_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6445fbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b0d2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkfield(fullfield, key):\n",
    "    parts = str(fullfield).split('|')\n",
    "    for part in parts:\n",
    "        if part.startswith(key+':'):\n",
    "            uniprot_parts = part.split(':')\n",
    "            upid = uniprot_parts[1]\n",
    "            if '-' in upid:\n",
    "                return upid[:upid.find('-')]\n",
    "            else:\n",
    "                return upid\n",
    "    return None\n",
    "\n",
    "def get_uniprot(row, protein_no):\n",
    "    uniprot = checkfield(row[f'protein_xref_{protein_no}'],'uniprotkb')\n",
    "    if uniprot is not None:\n",
    "        return uniprot\n",
    "    uniprot = checkfield(row[f'alternative_identifiers_{protein_no}'],'uniprotkb')\n",
    "    if uniprot is not None:\n",
    "        return uniprot\n",
    "    uniprot = checkfield(row[f'protein_alias_{protein_no}'],'uniprotkb')\n",
    "    if uniprot is not None:\n",
    "        return uniprot\n",
    "    return ''\n",
    "\n",
    "def load_hpidb_table(table_filename):\n",
    "    hpidb_data = pd.read_table(table_filename,encoding='latin1')\n",
    "    hpidb_data=hpidb_data.rename(columns={'# protein_xref_1':'protein_xref_1'})\n",
    "    ups_1 = []\n",
    "    ups_2 = []\n",
    "    for i in range(len(hpidb_data)):\n",
    "        up_1 = get_uniprot(hpidb_data.iloc[i],1)\n",
    "        up_2 = get_uniprot(hpidb_data.iloc[i],2)\n",
    "        if up_1.find('(gene name)') != -1 or up_2.find('(gene name)') != -1:\n",
    "            ups_1.append(\"\")\n",
    "            ups_2.append(\"\")        \n",
    "        else:\n",
    "            ups_1.append(up_1)\n",
    "            ups_2.append(up_2)\n",
    "    hpidb_data['uniprot_1'] = ups_1\n",
    "    hpidb_data['uniprot_2'] = ups_2\n",
    "    hpidb_data = hpidb_data.query('uniprot_1 != \"\" and uniprot_2 != \"\"')\n",
    "    return hpidb_data\n",
    "\n",
    "def get_taxid(taxid_string):\n",
    "    taxid = int(taxid_string.split('(')[0].replace('taxid:',''))\n",
    "    return taxid\n",
    "\n",
    "def get_species(taxid):\n",
    "    rank = ncbi.get_rank([taxid]) \n",
    "    if len(rank) > 0:\n",
    "        if rank[taxid] == 'species':\n",
    "            species = taxid\n",
    "        else:\n",
    "            ranks = ncbi.get_rank(ncbi.get_lineage(taxid))\n",
    "            potential_species = [r for r in ranks if ranks[r] == 'species']\n",
    "            species = np.min(potential_species)\n",
    "        return ncbi.get_taxid_translator([species])[species]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def species_mask_samples(sample_list):\n",
    "    species_1 = {}\n",
    "    species_2 = {}\n",
    "    spec_masked_samples = []\n",
    "    for sample_pair in sample_list:\n",
    "        id_1 = sample_pair.seq_record_1.id\n",
    "        id_2 = sample_pair.seq_record_2.id\n",
    "        if id_1 in uniprot_to_taxid and id_2 in uniprot_to_taxid:\n",
    "            taxid_1 = uniprot_to_taxid[id_1]\n",
    "            taxid_2 = uniprot_to_taxid[id_2]\n",
    "            sp1 = get_species(taxid_1)\n",
    "            sp2 = get_species(taxid_2)\n",
    "            if sp1 is not None and sp2 is not None:\n",
    "                spec_masked_samples.append([str(sp1), str(sp2), sample_pair.is_ppi])\n",
    "    return pd.DataFrame(spec_masked_samples, columns=['species_1','species_2','is_ppi'])\n",
    "\n",
    "hpi_pred = load_hpidb_table('data/0009_superkingdom_classification/hpidb_interologs.mitab_plus.txt')\n",
    "hpidb_data = load_hpidb_table('data/0009_superkingdom_classification/hpidb2.mitab.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c34817d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_j/jxj9zb555rx6r9825t1lmz_r000fpf/T/ipykernel_89925/3282808939.py:1: DtypeWarning: Columns (22,25,26,29,30,37,45,46,47,50,51,53) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  phibase_df = pd.read_csv('data/0009_superkingdom_classification/phi-base_current2.csv', encoding='latin-1')\n"
     ]
    }
   ],
   "source": [
    "phibase_df = pd.read_csv('data/0009_superkingdom_classification/phi-base_current2.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5894179b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hpidb_data_combined = pd.concat((hpidb_data, hpi_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2fb7a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniprot_to_taxid = {}\n",
    "\n",
    "for row in hpidb_data_combined.iloc:\n",
    "    taxid_1 = get_taxid(row['protein_taxid_1'])\n",
    "    taxid_2 = get_taxid(row['protein_taxid_2'])\n",
    "    up_1 = row['uniprot_1']\n",
    "    up_2 = row['uniprot_2']\n",
    "    # If there are multiple different taxids for a given ID, take the lowest one (as the higher one will \n",
    "    # correspond to a specific strain, whereas both are definitely )\n",
    "    if up_1 not in uniprot_to_taxid or (uniprot_to_taxid[up_1] != taxid_1 and taxid_1 < uniprot_to_taxid[up_1]):\n",
    "        uniprot_to_taxid[up_1] = taxid_1\n",
    "    if up_2 not in uniprot_to_taxid or (uniprot_to_taxid[up_2] != taxid_2 and taxid_2 < uniprot_to_taxid[up_2]):\n",
    "        uniprot_to_taxid[up_2] = taxid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "349310c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/0000_datasets_as_used_in_paper/HPIDB/HPIDB3_4mers.npz',allow_pickle=True)\n",
    "training=SampleList(data['training'])\n",
    "validation=SampleList(data['validation'])\n",
    "test=SampleList(data['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f12afc",
   "metadata": {},
   "source": [
    "## Species-masked data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1380e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_onehotencoding(all_df, train_df, valid_df, test_df):\n",
    "    enc = OneHotEncoder()\n",
    "    enc.fit(all_df)\n",
    "    enc_train = enc.transform(train_df).toarray()\n",
    "    enc_train_x = enc_train[:,:-2]\n",
    "    enc_train_y = train_df['is_ppi']\n",
    "    enc_valid = enc.transform(valid_df).toarray()\n",
    "    enc_valid_x = enc_valid[:,:-2]\n",
    "    enc_valid_y = valid_df['is_ppi']\n",
    "    enc_test = enc.transform(test_df).toarray()\n",
    "    enc_test_x = enc_test[:,:-2]\n",
    "    enc_test_y = test_df['is_ppi']\n",
    "    return (enc_train_x, enc_train_y, enc_valid_x, enc_valid_y, enc_test_x, enc_test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d78e2486",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask sequence with species\n",
    "spec_masked_df_train = species_mask_samples(training)\n",
    "spec_masked_df_validation = species_mask_samples(validation)\n",
    "spec_masked_df_test = species_mask_samples(test)\n",
    "spec_masked_df = pd.concat((spec_masked_df_train,spec_masked_df_validation,spec_masked_df_test))\n",
    "\n",
    "# one-hot encode the data for machine learning\n",
    "spec_masked_df_enc_train_x, spec_masked_df_enc_train_y,spec_masked_df_enc_valid_x, spec_masked_df_enc_valid_y, spec_masked_df_enc_test_x, spec_masked_df_enc_test_y = get_onehotencoding(spec_masked_df,\n",
    "spec_masked_df_train, spec_masked_df_validation ,spec_masked_df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b8e81e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf):\n",
    "    # row = truth, column = prediction\n",
    "    tn, fp = conf[0] # truth = negative\n",
    "    fn, tp = conf[1] # truth = positive\n",
    "    print('tp', tp, 'tn', tn, 'fp', fp, 'fn', fn)\n",
    "    print('f1',tp/(tp+0.5*(fp+fn)))\n",
    "    row_sums = conf.sum(axis=1)\n",
    "    conf = conf / row_sums[:, np.newaxis]\n",
    "    plt.imshow(conf, cmap='Blues')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.yticks([0,1])\n",
    "    plt.xticks([0,1])\n",
    "    midp = (np.amax(conf)+np.amin(conf))/2\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            if conf[i][j] > midp:\n",
    "                colour = 'w'\n",
    "            else:\n",
    "                colour = 'k'\n",
    "            plt.text(j,i,'{:.2f}'.format(conf[i][j]),c=colour)\n",
    "    plt.show()\n",
    "\n",
    "# Build a k-nearest neighbour model and train using the data in the given data directory.\n",
    "def build_knn_model(kneighbours, train_x, train_y, val_x, val_y, test_x, test_y, holdout):\n",
    "    clf = KNeighborsClassifier(n_neighbors=kneighbours, n_jobs=1).fit(train_x, train_y)\n",
    "    if holdout:\n",
    "        ys = clf.predict(test_x)\n",
    "        scores = clf.score(test_x, test_y)\n",
    "        cm = confusion_matrix(test_y, ys)\n",
    "        return scores, cm\n",
    "    else:\n",
    "        ys = clf.predict(val_x)\n",
    "        scores = clf.score(val_x, val_y)\n",
    "        cm = confusion_matrix(val_y, ys)\n",
    "        return scores, cm\n",
    "\n",
    "def run_knn(train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "    max_v = -math.inf\n",
    "    max_i_dist = 0\n",
    "    max_k = 5\n",
    "    vs_dist = np.zeros((max_k,))\n",
    "    for i in range(1, max_k):\n",
    "        print(i)\n",
    "        scores_temp, cm_temp = build_knn_model(i, train_x, train_y, val_x, val_y, test_x, test_y, False)\n",
    "        vs_dist[i] = scores_temp\n",
    "        if scores_temp > max_v:\n",
    "            max_v = scores_temp\n",
    "            max_i_dist = i\n",
    "    print('Number of neighbours vs. classification score')\n",
    "    plt.plot(vs_dist)\n",
    "    plt.xlabel('k (number of neighbours)')\n",
    "    plt.ylabel('Validation accuracy')\n",
    "    plt.show()\n",
    "    scores_dist, cm_dist = build_knn_model(max_i_dist, train_x, train_y, val_x, val_y, test_x, test_y, True)\n",
    "    print('Score:',scores_dist)\n",
    "    plot_confusion_matrix(cm_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ae17370",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_knn(spec_masked_df_enc_train_x, spec_masked_df_enc_train_y,\n",
    "                                           spec_masked_df_enc_valid_x, spec_masked_df_enc_valid_y,\n",
    "                                           spec_masked_df_enc_test_x, spec_masked_df_enc_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa5c827",
   "metadata": {},
   "source": [
    "## Build superkingdom data\n",
    "\n",
    "CGRs for sequences, labelled by superkingdom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "495a8046",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_specific_rank(taxid, rankname):\n",
    "    rank = ncbi.get_rank([taxid]) \n",
    "    if len(rank)>0:\n",
    "        if rank[taxid] == rankname:\n",
    "            species = taxid\n",
    "        else:\n",
    "            ranks = ncbi.get_rank(ncbi.get_lineage(taxid))\n",
    "            potential_species = [r for r in ranks if ranks[r] == rankname]\n",
    "            if len(potential_species) == 0:\n",
    "                return None\n",
    "            species = np.min(potential_species)\n",
    "        return ncbi.get_taxid_translator([species])[species]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "def remake_data(dataset, rank, k=4, debug=False):\n",
    "    new_dataset_x = []\n",
    "    new_dataset_y = []\n",
    "    for sample_pair in dataset:\n",
    "        id_1 = sample_pair.seq_record_1.id\n",
    "        id_2 = sample_pair.seq_record_2.id\n",
    "        if id_1 in uniprot_to_taxid and id_2 in uniprot_to_taxid:\n",
    "            taxid_1 = uniprot_to_taxid[id_1]\n",
    "            taxid_2 = uniprot_to_taxid[id_2]\n",
    "            rank_1 = get_specific_rank(taxid_1, rank)\n",
    "            rank_2 = get_specific_rank(taxid_2, rank)\n",
    "            if rank_1 is not None:\n",
    "                cgr_1 = make_cgr(str(sample_pair.seq_record_1.seq), k, True)\n",
    "                new_dataset_x.append(cgr_1)\n",
    "                new_dataset_y.append(rank_1)\n",
    "            if rank_2 is not None:\n",
    "                cgr_2 = make_cgr(str(sample_pair.seq_record_2.seq), k, True)\n",
    "                cgr_2 = cgr_2 / np.amax(cgr_2)\n",
    "                new_dataset_x.append(cgr_2)\n",
    "                new_dataset_y.append(rank_2)\n",
    "            if debug and len(new_dataset_y)>10:\n",
    "                break\n",
    "    return np.array(new_dataset_x)[:,:,:,None], new_dataset_y\n",
    "\n",
    "def encode_data(rank, k, debug=False):\n",
    "    spec_labelled_data_train_x, spec_labelled_data_train_y = remake_data(training, rank, k, debug)\n",
    "    enc = OneHotEncoder(handle_unknown='ignore')\n",
    "    enc_train = enc.fit_transform(np.array(spec_labelled_data_train_y).reshape(-1, 1)).toarray()\n",
    "    spec_labelled_data_validation_x, spec_labelled_data_validation_y = remake_data(validation, rank, k, debug)\n",
    "    spec_labelled_data_test_x, spec_labelled_data_test_y = remake_data(test, rank, k, debug)\n",
    "    enc_validation = enc.transform(np.array(spec_labelled_data_validation_y).reshape(-1, 1)).toarray()\n",
    "    enc_test = enc.transform(np.array(spec_labelled_data_test_y).reshape(-1, 1)).toarray()\n",
    "    val_inds = np.argwhere(np.sum(enc_validation,axis=1,dtype=int))[:,0]\n",
    "    test_inds = np.argwhere(np.sum(enc_test,axis=1,dtype=int))[:,0]\n",
    "    enc_validation=enc_validation[val_inds,:]\n",
    "    spec_labelled_data_validation_x=spec_labelled_data_validation_x[val_inds,:,:,:]\n",
    "    enc_test=enc_test[test_inds,:]\n",
    "    spec_labelled_data_test_x=spec_labelled_data_test_x[test_inds,:,:,:]\n",
    "    species_list = np.unique(spec_labelled_data_train_y)\n",
    "    class_weight_list = compute_class_weight(class_weight='balanced',classes=species_list,\n",
    "                                             y=spec_labelled_data_train_y)\n",
    "    class_weights = {i: class_weight_list[i] for i in range(len(np.unique(spec_labelled_data_train_y)))}\n",
    "    return spec_labelled_data_train_x, enc_train, spec_labelled_data_validation_x, \\\n",
    "        enc_validation, spec_labelled_data_test_x, enc_test, species_list, class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "beb0864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y, val_x, val_y, test_x, test_y, species_list, class_weights = encode_data('superkingdom',4)\n",
    "np.savez('data/0009_superkingdom_classification/superkingdom_4mers.npz',train_x=train_x,train_y=train_y,\n",
    "        val_x=val_x,val_y=val_y,\n",
    "         test_x=test_x,test_y=test_y,\n",
    "        species_list=species_list,class_weights=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d72b7bc",
   "metadata": {},
   "source": [
    "## Run parameter search\n",
    "\n",
    "Ran elsewhere for GPU access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f75093",
   "metadata": {},
   "source": [
    "## Holdout test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f11ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in results from GPU\n",
    "results_df=pd.read_csv(f'data/0009_superkingdom_classification/superkingdom_out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11be52ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conv_blocks</th>\n",
       "      <th>num_filters</th>\n",
       "      <th>num_conv_layers_per_block</th>\n",
       "      <th>kernel_width</th>\n",
       "      <th>dense_layer_depth</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>conv_batch_normalisation</th>\n",
       "      <th>dense_batch_normalisation</th>\n",
       "      <th>rate_of_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>epoch</th>\n",
       "      <th>max_val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>categorical_crossentropy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_categorical_crossentropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0.666540</td>\n",
       "      <td>0.667945</td>\n",
       "      <td>0.683215</td>\n",
       "      <td>0.683215</td>\n",
       "      <td>0.662116</td>\n",
       "      <td>1.166011</td>\n",
       "      <td>0.501906</td>\n",
       "      <td>0.501906</td>\n",
       "      <td>1.166011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>0.919588</td>\n",
       "      <td>0.121198</td>\n",
       "      <td>0.950609</td>\n",
       "      <td>0.950609</td>\n",
       "      <td>0.144717</td>\n",
       "      <td>0.267529</td>\n",
       "      <td>0.918445</td>\n",
       "      <td>0.918445</td>\n",
       "      <td>0.267529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.924543</td>\n",
       "      <td>0.204820</td>\n",
       "      <td>0.915693</td>\n",
       "      <td>0.915693</td>\n",
       "      <td>0.230340</td>\n",
       "      <td>0.400331</td>\n",
       "      <td>0.873476</td>\n",
       "      <td>0.873476</td>\n",
       "      <td>0.400331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.922256</td>\n",
       "      <td>0.214259</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.910742</td>\n",
       "      <td>0.250642</td>\n",
       "      <td>0.441605</td>\n",
       "      <td>0.863567</td>\n",
       "      <td>0.863567</td>\n",
       "      <td>0.441605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1024</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.163170</td>\n",
       "      <td>0.932326</td>\n",
       "      <td>0.932326</td>\n",
       "      <td>0.195568</td>\n",
       "      <td>0.239698</td>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.239698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>97</td>\n",
       "      <td>0.825457</td>\n",
       "      <td>0.629248</td>\n",
       "      <td>0.776917</td>\n",
       "      <td>0.776917</td>\n",
       "      <td>0.593193</td>\n",
       "      <td>0.552271</td>\n",
       "      <td>0.816311</td>\n",
       "      <td>0.816311</td>\n",
       "      <td>0.552271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>0.828506</td>\n",
       "      <td>0.571401</td>\n",
       "      <td>0.791519</td>\n",
       "      <td>0.791519</td>\n",
       "      <td>0.551607</td>\n",
       "      <td>0.517950</td>\n",
       "      <td>0.818979</td>\n",
       "      <td>0.818979</td>\n",
       "      <td>0.517950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>96</td>\n",
       "      <td>0.833841</td>\n",
       "      <td>0.604332</td>\n",
       "      <td>0.782377</td>\n",
       "      <td>0.782377</td>\n",
       "      <td>0.577377</td>\n",
       "      <td>0.535600</td>\n",
       "      <td>0.815168</td>\n",
       "      <td>0.815168</td>\n",
       "      <td>0.535600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>105</td>\n",
       "      <td>0.829268</td>\n",
       "      <td>0.602025</td>\n",
       "      <td>0.786821</td>\n",
       "      <td>0.786821</td>\n",
       "      <td>0.568174</td>\n",
       "      <td>0.531216</td>\n",
       "      <td>0.820503</td>\n",
       "      <td>0.820503</td>\n",
       "      <td>0.531216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>0.831555</td>\n",
       "      <td>0.678140</td>\n",
       "      <td>0.760284</td>\n",
       "      <td>0.760284</td>\n",
       "      <td>0.630891</td>\n",
       "      <td>0.584507</td>\n",
       "      <td>0.809070</td>\n",
       "      <td>0.809070</td>\n",
       "      <td>0.584507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  conv_blocks  num_filters  num_conv_layers_per_block  \\\n",
       "0             0            4         1024                          2   \n",
       "1             1            4         1024                          2   \n",
       "2             2            4         1024                          2   \n",
       "3             3            4         1024                          2   \n",
       "4             4            4         1024                          2   \n",
       "..          ...          ...          ...                        ...   \n",
       "495         495            1           64                          2   \n",
       "496         496            1           64                          2   \n",
       "497         497            1           64                          2   \n",
       "498         498            1           64                          2   \n",
       "499         499            1           64                          2   \n",
       "\n",
       "     kernel_width  dense_layer_depth  dense_layers  conv_batch_normalisation  \\\n",
       "0               3                 64             3                         1   \n",
       "1               3                 64             3                         1   \n",
       "2               3                 64             3                         1   \n",
       "3               3                 64             3                         1   \n",
       "4               3                 64             3                         1   \n",
       "..            ...                ...           ...                       ...   \n",
       "495             3                 24             0                         0   \n",
       "496             3                 24             0                         0   \n",
       "497             3                 24             0                         0   \n",
       "498             3                 24             0                         0   \n",
       "499             3                 24             0                         0   \n",
       "\n",
       "     dense_batch_normalisation  rate_of_dropout  ...  epoch  max_val_acc  \\\n",
       "0                            1              0.3  ...      5     0.666540   \n",
       "1                            1              0.3  ...     23     0.919588   \n",
       "2                            1              0.3  ...     17     0.924543   \n",
       "3                            1              0.3  ...     18     0.922256   \n",
       "4                            1              0.3  ...     19     0.929878   \n",
       "..                         ...              ...  ...    ...          ...   \n",
       "495                          0              0.5  ...     97     0.825457   \n",
       "496                          0              0.5  ...    130     0.828506   \n",
       "497                          0              0.5  ...     96     0.833841   \n",
       "498                          0              0.5  ...    105     0.829268   \n",
       "499                          0              0.5  ...     75     0.831555   \n",
       "\n",
       "         loss       acc  categorical_accuracy  categorical_crossentropy  \\\n",
       "0    0.667945  0.683215              0.683215                  0.662116   \n",
       "1    0.121198  0.950609              0.950609                  0.144717   \n",
       "2    0.204820  0.915693              0.915693                  0.230340   \n",
       "3    0.214259  0.910742              0.910742                  0.250642   \n",
       "4    0.163170  0.932326              0.932326                  0.195568   \n",
       "..        ...       ...                   ...                       ...   \n",
       "495  0.629248  0.776917              0.776917                  0.593193   \n",
       "496  0.571401  0.791519              0.791519                  0.551607   \n",
       "497  0.604332  0.782377              0.782377                  0.577377   \n",
       "498  0.602025  0.786821              0.786821                  0.568174   \n",
       "499  0.678140  0.760284              0.760284                  0.630891   \n",
       "\n",
       "     val_loss   val_acc  val_categorical_accuracy  \\\n",
       "0    1.166011  0.501906                  0.501906   \n",
       "1    0.267529  0.918445                  0.918445   \n",
       "2    0.400331  0.873476                  0.873476   \n",
       "3    0.441605  0.863567                  0.863567   \n",
       "4    0.239698  0.929878                  0.929878   \n",
       "..        ...       ...                       ...   \n",
       "495  0.552271  0.816311                  0.816311   \n",
       "496  0.517950  0.818979                  0.818979   \n",
       "497  0.535600  0.815168                  0.815168   \n",
       "498  0.531216  0.820503                  0.820503   \n",
       "499  0.584507  0.809070                  0.809070   \n",
       "\n",
       "     val_categorical_crossentropy  \n",
       "0                        1.166011  \n",
       "1                        0.267529  \n",
       "2                        0.400331  \n",
       "3                        0.441605  \n",
       "4                        0.239698  \n",
       "..                            ...  \n",
       "495                      0.552271  \n",
       "496                      0.517950  \n",
       "497                      0.535600  \n",
       "498                      0.531216  \n",
       "499                      0.584507  \n",
       "\n",
       "[500 rows x 27 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd7e2f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>conv_blocks</th>\n",
       "      <th>num_filters</th>\n",
       "      <th>num_conv_layers_per_block</th>\n",
       "      <th>kernel_width</th>\n",
       "      <th>dense_layer_depth</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>conv_batch_normalisation</th>\n",
       "      <th>dense_batch_normalisation</th>\n",
       "      <th>rate_of_dropout</th>\n",
       "      <th>...</th>\n",
       "      <th>epoch</th>\n",
       "      <th>max_val_acc</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>categorical_crossentropy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>val_categorical_crossentropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>115</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>0.949314</td>\n",
       "      <td>0.062419</td>\n",
       "      <td>0.971813</td>\n",
       "      <td>0.971813</td>\n",
       "      <td>0.077183</td>\n",
       "      <td>0.255558</td>\n",
       "      <td>0.942454</td>\n",
       "      <td>0.942454</td>\n",
       "      <td>0.255558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>116</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.100834</td>\n",
       "      <td>0.956831</td>\n",
       "      <td>0.956831</td>\n",
       "      <td>0.123142</td>\n",
       "      <td>0.183999</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.183999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>117</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>18</td>\n",
       "      <td>0.948933</td>\n",
       "      <td>0.063076</td>\n",
       "      <td>0.973083</td>\n",
       "      <td>0.973083</td>\n",
       "      <td>0.079529</td>\n",
       "      <td>0.302936</td>\n",
       "      <td>0.948933</td>\n",
       "      <td>0.948933</td>\n",
       "      <td>0.302936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>0.937119</td>\n",
       "      <td>0.118746</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.132777</td>\n",
       "      <td>0.462827</td>\n",
       "      <td>0.897104</td>\n",
       "      <td>0.897104</td>\n",
       "      <td>0.462827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>119</td>\n",
       "      <td>3</td>\n",
       "      <td>512</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>512</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>0.948552</td>\n",
       "      <td>0.092838</td>\n",
       "      <td>0.965846</td>\n",
       "      <td>0.965846</td>\n",
       "      <td>0.104901</td>\n",
       "      <td>0.202754</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.946646</td>\n",
       "      <td>0.202754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  conv_blocks  num_filters  num_conv_layers_per_block  \\\n",
       "115         115            3          512                          1   \n",
       "116         116            3          512                          1   \n",
       "117         117            3          512                          1   \n",
       "118         118            3          512                          1   \n",
       "119         119            3          512                          1   \n",
       "\n",
       "     kernel_width  dense_layer_depth  dense_layers  conv_batch_normalisation  \\\n",
       "115             5                512             0                         1   \n",
       "116             5                512             0                         1   \n",
       "117             5                512             0                         1   \n",
       "118             5                512             0                         1   \n",
       "119             5                512             0                         1   \n",
       "\n",
       "     dense_batch_normalisation  rate_of_dropout  ...  epoch  max_val_acc  \\\n",
       "115                          1              0.7  ...     19     0.949314   \n",
       "116                          1              0.7  ...     15     0.946646   \n",
       "117                          1              0.7  ...     18     0.948933   \n",
       "118                          1              0.7  ...     16     0.937119   \n",
       "119                          1              0.7  ...     17     0.948552   \n",
       "\n",
       "         loss       acc  categorical_accuracy  categorical_crossentropy  \\\n",
       "115  0.062419  0.971813              0.971813                  0.077183   \n",
       "116  0.100834  0.956831              0.956831                  0.123142   \n",
       "117  0.063076  0.973083              0.973083                  0.079529   \n",
       "118  0.118746  0.954545              0.954545                  0.132777   \n",
       "119  0.092838  0.965846              0.965846                  0.104901   \n",
       "\n",
       "     val_loss   val_acc  val_categorical_accuracy  \\\n",
       "115  0.255558  0.942454                  0.942454   \n",
       "116  0.183999  0.946646                  0.946646   \n",
       "117  0.302936  0.948933                  0.948933   \n",
       "118  0.462827  0.897104                  0.897104   \n",
       "119  0.202754  0.946646                  0.946646   \n",
       "\n",
       "     val_categorical_crossentropy  \n",
       "115                      0.255558  \n",
       "116                      0.183999  \n",
       "117                      0.302936  \n",
       "118                      0.462827  \n",
       "119                      0.202754  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means=results_df.groupby('seed_i',as_index=False).mean()\n",
    "seed_i=means.sort_values(by='val_categorical_accuracy',ascending=False).iloc[0]['seed_i']\n",
    "results_df.query(f'seed_i=={seed_i}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "95652f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params={}\n",
    "for key in simple_cgr_model.possible_params:\n",
    "    if key in ['rate_of_dropout','rate_of_conv_dropout','learning_rate']:\n",
    "        best_params[key]=means.sort_values('val_categorical_accuracy').iloc[-1][key]\n",
    "    else:\n",
    "        best_params[key]=int(means.sort_values('val_categorical_accuracy').iloc[-1][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f166ee57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'conv_blocks': 3,\n",
       " 'num_filters': 512,\n",
       " 'num_conv_layers_per_block': 1,\n",
       " 'kernel_width': 5,\n",
       " 'dense_layer_depth': 512,\n",
       " 'dense_layers': 0,\n",
       " 'conv_batch_normalisation': 1,\n",
       " 'dense_batch_normalisation': 1,\n",
       " 'rate_of_dropout': 0.7,\n",
       " 'rate_of_conv_dropout': 0.3,\n",
       " 'conv_use_bias': 0,\n",
       " 'dense_use_bias': 1,\n",
       " 'learning_rate': 0.001,\n",
       " 'optimizer': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e33deb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('data/0000_datasets_as_used_in_paper/Taxonomy/superkingdom_4mers.npz',allow_pickle=True)\n",
    "train_x = data['train_x']\n",
    "train_y = data['train_y']\n",
    "val_x = data['val_x']\n",
    "val_y = data['val_y']\n",
    "test_x = data['test_x']\n",
    "test_y = data['test_y']\n",
    "species_list = data['species_list']\n",
    "class_weights = data['class_weights'].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c93228",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_cgr_model.test_params(best_params,species_list,0,\n",
    "                             train_x, train_y, val_x, val_y, test_x, test_y, class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1c691f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
